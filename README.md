CLIP-style visionâ€“language model trained on Flickr30k
PyTorch Lightning implementation with contrastive loss, retrieval evaluation, and qualitative logging.